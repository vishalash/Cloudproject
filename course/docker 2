

Docker
********

	The virtulisation solves the problem of O.S. taking the whole resources on bare metal.
	Virtulisation gives a layer on which multiple O.S. can be installed.

	But each os is used for a specific job but waste some resources.
There is con in virtulisation.
	Suppose we installed a redhat for a mail server and then again a redhat for mail server and many more.
	but we duplicate O.S. ... as os use many ram.
if we give 2 gb to os then if 1 gb is used for server but 1 gb will waste for rest of os.

it just share Hardware 
*** But conatiner technology not just share hardware but the o.s. also.

	
        
                     *Multiple O.S. 
                ______________________________________   < Layer(Docker Engine)
                       O.S.
		-------------------------------------
                  Physical Hardware


*(It uses kernel of below o.s.)   // the image only contains some software and uses below os kernel.
as it shares kernel it has same storage and ram as below os.. as kernel tells what resources are available.

	For the redhat(Below os) the above os are just normal process as some other command.

	But this Process is whole new os.
	Process shares resources(hardware,kernel etc.)

Client don't care where the os is running.

Virtulisation needs a long time to install os.

There above os is called conatiners.

  dockers company introduce container in a easy way.

  But the redhat can use redhat kernel But how  #Ubuntu is using redhat kernel.

  after v3 kernel linux kernel has standarised so docker needs v3 kernel so rhel 6 as uses v2 kenel it do not support docker.

	so, kernel is main criertia for docker.
so win and mac can not support docker.
hence microsoft collobrated with docker for making kernel in a different way.

	
#uname -r  // kernel

after running container

ps aux | grep bash

echo $SHELL

we get cmd coz bash started as we start contaoner 
  ubuntu  /bin/bash  --by default

  	
**name space is used for this technology.

	ubuntu date run date as a new os start run and end.
  If we kill bash process the docker will stop.


  bootodocker is used to manage docker in windows. docker engine is only availabe for linux.

  #top  --to see processes

but only one process is running that is bash.

 	os is never boot as process do not boot. It feels like an os but actually an process.

**conatiner support this process in process by name space technology.
to save from single point of failure(base os stop)--	
	in virtulisation--migration
	in docker--cluster(Swarm, Kubernities)

	Thin os---EHEVHE essi haper V
 *************************** 
		
	cd /proc/(pid)

**root folder in conatiner process / is linked

		when we run a command in linux process know where is /
Docker link / of container to some other process.

*****************************

	
	docker run -dit ubuntu /bin/bash


if we want to run command inside image

to automate -- docker exec -it cranky_nobel date


networking in docker
********************

docker made a bridge in our system by default.

brctl addif docker0 enp0s3

ifconfig enp0s3 0

dhclient enp0s3



#net-tools for ifconfig
remove enp0s3 ip

dhclient -v docker0

ip addr -- to see ip

But we cannot ip in container as sercurity denies it
#Add this when running container    --previleged=true

ifconfig eth0

#docker daemon -H fd:// --bip=192.168.56.106/24 a   -- to run docker

	
In main os if we have some folder


but if we want some folder to be shared i the os 
docker run -v /folder:/newfolder ubuntu

	
it automatically mount folder into a newfolder in the container










































